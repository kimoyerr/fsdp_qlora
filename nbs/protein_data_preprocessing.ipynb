{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess ProteinGym Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'RL40A_YEAST_Roscoe_2014', 'A0A2Z5U3Z0_9INFA_Wu_2014', 'A0A2Z5U3Z0_9INFA_Wu_2014', 'A0A2Z5U3Z0_9INFA_Wu_2014', 'A0A2Z5U3Z0_9INFA_Wu_2014', 'A0A2Z5U3Z0_9INFA_Wu_2014', 'A0A2Z5U3Z0_9INFA_Wu_2014', 'ENVZ_ECOLI_Ghose_2023', 'ENVZ_ECOLI_Ghose_2023', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'DYR_ECOLI_Thompson_2019', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'IF1_ECOLI_Kelsic_2016', 'GRB2_HUMAN_Faure_2021', 'GRB2_HUMAN_Faure_2021', 'A0A1I9GEU1_NEIME_Kennouche_2019', 'A0A1I9GEU1_NEIME_Kennouche_2019', 'A0A1I9GEU1_NEIME_Kennouche_2019', 'A0A1I9GEU1_NEIME_Kennouche_2019', 'A0A1I9GEU1_NEIME_Kennouche_2019', 'A0A1I9GEU1_NEIME_Kennouche_2019', 'P84126_THETH_Chan_2017', 'P84126_THETH_Chan_2017', 'P84126_THETH_Chan_2017', 'P84126_THETH_Chan_2017', 'P84126_THETH_Chan_2017', 'P84126_THETH_Chan_2017', 'RASH_HUMAN_Bandaru_2017']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all csv files in proteingym folder including subfolders\n",
    "path = \"/ConFit/data/proteingym\"\n",
    "csv_files = [f for f in glob.glob(path + \"/**/*.csv\", recursive=True)]\n",
    "csv_files\n",
    "\n",
    "\n",
    "# Get folder name\n",
    "dsm_names = [os.path.basename(os.path.dirname(f)) for f in csv_files]\n",
    "print(dsm_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_dsm = \"RASH_HUMAN_Bandaru_2017\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ConFit/data/proteingym/RL40A_YEAST_Roscoe_2014/data.csv\n",
      "/ConFit/data/proteingym/A0A2Z5U3Z0_9INFA_Wu_2014/data.csv\n",
      "/ConFit/data/proteingym/ENVZ_ECOLI_Ghose_2023/data.csv\n",
      "/ConFit/data/proteingym/DYR_ECOLI_Thompson_2019/data.csv\n",
      "/ConFit/data/proteingym/IF1_ECOLI_Kelsic_2016/data.csv\n",
      "/ConFit/data/proteingym/GRB2_HUMAN_Faure_2021/data.csv\n",
      "/ConFit/data/proteingym/A0A1I9GEU1_NEIME_Kennouche_2019/data.csv\n",
      "/ConFit/data/proteingym/P84126_THETH_Chan_2017/data.csv\n",
      "/ConFit/data/proteingym/RASH_HUMAN_Bandaru_2017/RASH_HUMAN_Bandaru_2017.csv\n",
      "/ConFit/data/proteingym/RASH_HUMAN_Bandaru_2017/RASH_HUMAN_Bandaru_2017.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>mutated_sequence</th>\n",
       "      <th>DMS_score</th>\n",
       "      <th>DMS_score_bin</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2L</td>\n",
       "      <td>MLEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.054586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2C</td>\n",
       "      <td>MCEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2D</td>\n",
       "      <td>MDEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.080530</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2E</td>\n",
       "      <td>MEEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.123798</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2F</td>\n",
       "      <td>MFEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.030497</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mutant                                   mutated_sequence  DMS_score  \\\n",
       "0    T2L  MLEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...  -0.054586   \n",
       "1    T2C  MCEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...   0.016885   \n",
       "2    T2D  MDEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...  -0.080530   \n",
       "3    T2E  MEEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...  -0.123798   \n",
       "4    T2F  MFEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...  -0.030497   \n",
       "\n",
       "   DMS_score_bin  id  \n",
       "0              1   0  \n",
       "1              1   1  \n",
       "2              1   2  \n",
       "3              1   3  \n",
       "4              1   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>seq</th>\n",
       "      <th>log_fitness</th>\n",
       "      <th>DMS_score_bin</th>\n",
       "      <th>PID</th>\n",
       "      <th>mutant_0</th>\n",
       "      <th>performance</th>\n",
       "      <th>n_mut</th>\n",
       "      <th>mutated_position</th>\n",
       "      <th>n_mut_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2L</td>\n",
       "      <td>MLEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.054586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>T2L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2C</td>\n",
       "      <td>MCEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>T2C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2D</td>\n",
       "      <td>MDEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.08053</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>T2D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2E</td>\n",
       "      <td>MEEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.123798</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>T2E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2F</td>\n",
       "      <td>MFEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...</td>\n",
       "      <td>-0.030497</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>T2F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mutant                                                seq log_fitness  \\\n",
       "1    T2L  MLEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...   -0.054586   \n",
       "2    T2C  MCEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...    0.016885   \n",
       "3    T2D  MDEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...    -0.08053   \n",
       "4    T2E  MEEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...   -0.123798   \n",
       "5    T2F  MFEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVI...   -0.030497   \n",
       "\n",
       "  DMS_score_bin  PID mutant_0 performance  n_mut mutated_position  n_mut_2  \n",
       "1             1    1      T2L         NaN      1                1        1  \n",
       "2             1    2      T2C         NaN      1                1        1  \n",
       "3             1    3      T2D         NaN      1                1        1  \n",
       "4             1    4      T2E         NaN      1                1        1  \n",
       "5             1    5      T2F         NaN      1                1        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for csv_file in csv_files:\n",
    "    # Only use data.csv files\n",
    "    if (\"data.csv\" not in csv_file) and  (sel_dsm + \".csv\" not in csv_file):\n",
    "        continue\n",
    "    print(csv_file)\n",
    "    # Get folder name\n",
    "    dsm_name = os.path.basename(os.path.dirname(csv_file))\n",
    "    if dsm_name != sel_dsm or \"data.csv\" in csv_file or \"wt.fasta\" in csv_file:\n",
    "        continue\n",
    "\n",
    "    print(csv_file)\n",
    "\n",
    "    orig_df = pd.read_csv(csv_file)\n",
    "    orig_df[\"id\"] = orig_df.index\n",
    "    display(orig_df.head())\n",
    "\n",
    "    # Rename some columns\n",
    "    new_df = orig_df.rename(columns={\"id\": \"PID\", \"DMS_score\": \"log_fitness\", \"mutated_sequence\":\"seq\"})\n",
    "\n",
    "    # Convert PID to int\n",
    "    new_df[\"PID\"] = new_df[\"PID\"].astype(int)\n",
    "\n",
    "    # Split the mutant column into multiple columns based on the \":\"\n",
    "    tmp_mut_cols = new_df[\"mutant\"].str.split(\":\", expand=True).add_prefix(\"mutant_\")\n",
    "    new_df = pd.concat([new_df, tmp_mut_cols], axis=1)\n",
    "\n",
    "    # Calculate the WT sequence from the first mutated sequence\n",
    "    if \"mutant_0\" in new_df.columns:\n",
    "        sel_col = \"mutant_0\"\n",
    "    else:\n",
    "        sel_col = \"mutant\"\n",
    "    all_mut_cols = [col for col in new_df.columns if \"mutant_\" in col]\n",
    "\n",
    "    # Get the mutant positions and amino acids for all mutants\n",
    "    mut_df_1 = pd.DataFrame(columns=[\"mut_pos\", \"wt_aa\", \"mut_aa\"])\n",
    "    for sel_col in all_mut_cols:\n",
    "        get_mut_pos = int(new_df[sel_col][0][1:-1])\n",
    "        get_wt_aa = new_df[sel_col][0][0]\n",
    "        get_mut_aa = new_df[sel_col][0][-1]\n",
    "        sel_mut_df = pd.DataFrame({\"mut_pos\": get_mut_pos, \"wt_aa\": get_wt_aa, \"mut_aa\": get_mut_aa}, index=[0])\n",
    "        mut_df_1 = pd.concat([mut_df_1, sel_mut_df], ignore_index=True)\n",
    "\n",
    "    # Order the dataframe by mut_pos\n",
    "    mut_df_1 = mut_df_1.sort_values(by=\"mut_pos\")\n",
    "    \n",
    "    # Add a new WT row\n",
    "    wt_row = new_df.iloc[0].copy()\n",
    "    # Iterate over the mutations and add them to the WT sequence\n",
    "    for i, row in mut_df_1.iterrows():\n",
    "        get_mut_pos = row[\"mut_pos\"]\n",
    "        get_wt_aa = row[\"wt_aa\"]\n",
    "        wt_row[\"seq\"] = wt_row[\"seq\"][:get_mut_pos-1] + get_wt_aa + wt_row[\"seq\"][get_mut_pos:]\n",
    "    wt_row[all_mut_cols] = \"WT\"\n",
    "    wt_row[\"mutant\"] = \"WT\"\n",
    "    wt_row[\"log_fitness\"] = 1\n",
    "    wt_row[\"performance\"] = \"-\"\n",
    "    # Add the WT row to the dataframe\n",
    "    new_df = pd.concat([wt_row.to_frame().T, new_df], ignore_index=True)\n",
    "\n",
    "    # Reset PID column\n",
    "    new_df[\"PID\"] = new_df.index\n",
    "\n",
    "    # Find the number of mutations compared to the first sequence\n",
    "    new_df[\"n_mut\"] = new_df[\"seq\"].apply(lambda x: sum(1 for a, b in zip(new_df[\"seq\"][0], x) if a != b))\n",
    "    new_df.head()\n",
    "\n",
    "    # Get mutated positions\n",
    "    new_df[\"mutated_position\"] = new_df.apply(lambda x: [i for i in range(len(x[\"seq\"])) if x[\"seq\"][i] != new_df[\"seq\"][0][i]], axis=1)\n",
    "    # Convert to string separated by commas\n",
    "    new_df[\"mutated_position\"] = new_df[\"mutated_position\"].apply(lambda x: \",\".join(map(str, x)))\n",
    "    new_df.head()\n",
    "\n",
    "    # Assert if the number of mutations from the \"mutant\"  column is the same as the number of mutations\n",
    "    # calculated from the sequence\n",
    "    new_df[\"n_mut_2\"] = new_df[\"mutant\"].apply(lambda x: len(x.split(\":\")))\n",
    "    # assert (far_df[\"n_mut\"] == far_df[\"n_mut_2\"]).all()\n",
    "    new_df.head()\n",
    "\n",
    "    # Replace \":\" in the mutant column with \";\"\n",
    "    new_df[\"mutant\"] = new_df[\"mutant\"].str.replace(\":\", \";\")\n",
    "\n",
    "    # Find row with no mutations and write the seq to a fasta file named \"wt.fasta\"\n",
    "    wt_seq = new_df[new_df[\"n_mut\"] == 0][\"seq\"].values[0]\n",
    "    with open(os.path.join(path, dsm_name,  \"wt.fasta\"), \"w\") as f:\n",
    "        f.write(\">wt\\n\")\n",
    "        f.write(wt_seq)\n",
    "\n",
    "    # Remove rows with no mutations\n",
    "    new_df = new_df[new_df[\"n_mut\"] > 0]\n",
    "\n",
    "    # Write to file\n",
    "    display(new_df.head())\n",
    "    new_df.to_csv(os.path.join(path, dsm_name,  \"data.csv\"), index=False)\n",
    "    \n",
    "    # Copy folder to the /data folder\n",
    "    os.system(f\"cp -r {os.path.join(path, dsm_name)} /ConFit/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(data_dir, seed, shots, frac=0.5):\n",
    "    '''\n",
    "    sample the train data and test data\n",
    "    :param seed: sample seed\n",
    "    :param frac: the fraction of testing data, default to 0.2\n",
    "    :param shot: the size of training data\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(f\"{data_dir}/data.csv\", index_col=0)\n",
    "    print(data.shape)\n",
    "    if frac > 0:\n",
    "        test_data = data.sample(frac=frac, random_state=seed)\n",
    "        train_data = data.drop(test_data.index)\n",
    "    elif frac == 0:\n",
    "        # Shuffle the data\n",
    "        data = data.sample(frac=1, random_state=seed)\n",
    "        train_data = data\n",
    "        test_data = pd.DataFrame()\n",
    "    else:\n",
    "        data = data.sample(frac=1, random_state=seed)\n",
    "        train_data = data\n",
    "        test_data = pd.DataFrame()\n",
    "    print(train_data.shape)\n",
    "\n",
    "    # Create a list of shots from a starting number and incrementing it until the training data is exhausted\n",
    "    shots_list = np.arange(shots[\"starting_shots\"], len(train_data), shots[\"increment\"])\n",
    "    \n",
    "    for shot in shots_list:\n",
    "        kshot_data = train_data.sample(n=shot, random_state=seed)\n",
    "        assert len(kshot_data) == shot, (\n",
    "            f'expected {shot} train examples, received {len(train_data)}')\n",
    "        kshot_val_data = train_data.drop(kshot_data.index)\n",
    "        kshot_data.to_csv(f\"{data_dir}/train_{shot}_shot.csv\")\n",
    "        kshot_val_data.to_csv(f\"{data_dir}/val_{shot}_shot.csv\")\n",
    "    else:\n",
    "        train_data.to_csv(f\"{data_dir}/train.csv\")\n",
    "        \n",
    "    test_data.to_csv(f\"{data_dir}/test.csv\")\n",
    "\n",
    "\n",
    "def split_train(data_dir, n_splits=5):\n",
    "    '''\n",
    "    five equal split training data, one of which will be used as validation set when training ConFit\n",
    "    '''\n",
    "    train = pd.read_csv(f\"{data_dir}/train.csv\", index_col=0)\n",
    "    tlen = int(np.ceil(len(train) / n_splits))\n",
    "    start = 0\n",
    "    for i in range(1, n_splits):\n",
    "        csv = train[start:start + tlen]\n",
    "        start += tlen\n",
    "        csv.to_csv(f\"{data_dir}/train_{i}.csv\")\n",
    "    csv = train[start:]\n",
    "    csv.to_csv(f\"{data_dir}/train_{n_splits}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3134, 9)\n",
      "(1567, 9)\n"
     ]
    }
   ],
   "source": [
    "# Use the full data for training\n",
    "protein_gym_dir = \"/ConFit/data/proteingym/\"\n",
    "test_fraction = 0.5\n",
    "\n",
    "# Dictionary for creating shots\n",
    "shots = {}\n",
    "shots[\"starting_shots\"] = 48\n",
    "shots[\"increment\"] = 48\n",
    "\n",
    "sample_data(os.path.join(protein_gym_dir,sel_dsm), seed=42, shots=shots, frac=test_fraction)\n",
    "\n",
    "# Split the training data into 2 folds\n",
    "# split_train(os.path.join(protein_gym_dir,sel_dsm), n_splits=2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
